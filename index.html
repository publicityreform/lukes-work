<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <!-- Meta tags for SEO and social sharing -->
    <link rel="canonical" href="https://publicityreform.github.io/lukes-work/" />
    <meta name="description" content="luke fischbeck's portfolio" />
    <meta name="robots" content="index,follow" />
    <meta property="og:title" content="Luke's Work" />
    <meta property="og:type" content="article" />
    <meta property="og:url" content="https://publicityreform.github.io/lukes-work/" />
    <meta property="og:description" content="luke fischbeck's portfolio" />
    <meta
      property="og:image"
      content="https://cdn.glitch.global/61c0af97-9b71-4785-8528-358ec76ada8e/IMG_8577.jpeg?v=1693514066884"
    />
    <meta name="twitter:card" content="summary" />
    <title>luke fischbeck's portfolio</title>

    <!-- import the webpage's stylesheet -->
    <link rel="stylesheet" href="/lukes-work/style.css" />

    <!-- import the webpage's javascript file -->
    <script src="/lukes-work/script.js" defer></script>
  </head>
  <body>
    <!-- this is the start of content -->
    <div id="container">
      <div id="top">
        <img
          class="full"
          alt="Animation of a mockingbird jumping into the air and turning to fall, colorized to show the direction of optical flow."
          src="https://cdn.glitch.global/a8abba79-5fe1-408e-a0a9-e56faa999b8e/mockingbird-clean.gif?v=1652458058362"
        />
      </div>
      <div class="complaint">
        <h1>Luke Fischbeck's<br />work (As of <span id="date"></span>)</h1>
        <p>
          I work collaboratively and over long durations, to gather pieces into
          collections whose formal status as artworks happen in
          situation-specific ways as one possible version among many.<br /><br />Here
          are a few examples. For more, please visit
          <a href="https://luckydragons.org" target="_blank"
            >https://luckydragons.org</a
          >, a comprehensive archive that I think gives good context for what I
          do.
        </p>
      </div>
      <div id="main">
        <img
          alt="Image of a polluted river in the shape of a human body"
          class="icon"
          src="/lukes-work/media/IMG_8577.jpeg"
        />
        <div class="text">
          <h1>Sentences About Rivers and Cancers</h1>
          <p>
            (audio, text, installation. 2022-ongoing)
            <br />
            <br />

            A catalog of the metaphors and conditions shared between rivers and
            cancers, the environmental and financial toxicities that precede and
            accompany illness, and the enduring contaminations that cancer and
            its treatment produce. The conditions of the living river become
            conditions for research. This is a watery analysis, thinking with
            bodies as pressurized wet salty things to better understand evidence
            of interbeing, entanglement, and porosity; listening intently for
            <i>nonpoint source</i> pollution: seeping, draining runoff and
            sediment, or, how rivers and bodies circulate together. A
            collaboration with artist-researcher Sarah Rara, this work draws on
            personal experiences of cancer treatment and care, and is informed
            by time spent living in close proximity to the Hoosic river, which
            flows through the ancestral lands of the Muh-he-con-ne-ok (Mohican)
            people: <i>The People of the Waters that Are Never Still</i>. As a
            collection-in-progress, the work includes site-specific sound works
            (a soundwalk, an installation), images, and texts.<br /><br /><a
              href="https://nonpointsource.glitch.me"
              target="_blank"
              >link to browser version</a
            >
          </p>
        </div>

        <img
          class="icon"
          alt="Two images of a mockingbird in mid-jump, one is photographic, the other, layered on top but slightly offset, is colorized to show the direction of optical flow."
          src="https://cdn.glitch.global/a8abba79-5fe1-408e-a0a9-e56faa999b8e/mockingbird-crop.png?v=1652458057999"
        />
        <div class="text">
          <h1>Mockingbirds</h1>
          <audio controls>
            <source
              src="https://cdn.glitch.global/a8abba79-5fe1-408e-a0a9-e56faa999b8e/41624091733113-1.mp3?v=1652550379957"
            />
          </audio>
          <p>
            (video, software, text, 2021-2022)
            <br /><br />
            A meditative analysis of Mockingbird gestures—song and dance—to get
            at notions of completion, continuity and repair that provide the
            rationale for countless machine learning tasks. Through video,
            software, text, and intervention (singing-with), this project
            considers computational techniques which turn from analysis to
            repair, such as flow prediction, gap in-filling, noise removal, and
            voice separation, in light of interspecies relationships and the
            co-construction of sensory worlds. This project is part of a larger
            research program that explores the relationship between perception,
            attention, and memory, and how these cognitive functions are modeled
            in artificial intelligence.
            <br /><br />
            <a href="https://vimeo.com/525096901" target="_blank"
              >Link to video</a
            >
            <br /><br />
            <a href="https://doi.org/10.1386/tear_00066_1" target="_blank"
              >Link to paper</a
            >
          </p>
        </div>
        <img
          class="icon"
          alt="A young man listens to a girl speaking. Both figures are surrounded by the branches of a flowering tree."
          src="https://cdn.glitch.global/a8abba79-5fe1-408e-a0a9-e56faa999b8e/Brody-After-Yang.webp?v=1652457965356"
        />
        <div class="text">
          <h1>After Yang</h1>
          <audio controls>
            <source
              src="https://cdn.glitch.global/a8abba79-5fe1-408e-a0a9-e56faa999b8e/Yang_Mika_AI_Version.mp3?v=1652457978512"
            />
          </audio>
          <audio controls>
            <source
              src="https://cdn.glitch.global/a8abba79-5fe1-408e-a0a9-e56faa999b8e/Yang_Eternal_AI_Version.mp3?v=1652457980488"
            />
          </audio>
          <audio controls>
            <source
              src="https://cdn.glitch.global/a8abba79-5fe1-408e-a0a9-e56faa999b8e/Mizuiro_Memory_AI_Version.mp3?v=1652457980530"
            />
          </audio>
          <p>
            Sound for the film <i>After Yang</i> (2022, dir. Kogonada). Working
            in collaboration with composer Aska Matsumiya, I developed AI
            processes—automating pattern recognition, analysis and resynthesis
            of the film’s score—to create audible artifacts that extended the
            film’s speculation as to the collapsing boundary between analysis
            and emotion, particularly in terms of memory, relation, and loss.
          </p>
        </div>
        <img
          class="icon"
          alt="Two performers standing in a rocky canyon in front of a small seated audience. Each performer is using a wand-like apparatus to suspend a large irridescent bubble."
          src="https://cdn.glitch.global/a8abba79-5fe1-408e-a0a9-e56faa999b8e/floating631.jpeg?v=1652469376565"
        />
        <div class="text">
          <h1>The Wheel</h1>
          <audio controls>
            <source
              src="https://cdn.glitch.global/a8abba79-5fe1-408e-a0a9-e56faa999b8e/LD-kumoko.mp3?v=1652469385816"
            />
          </audio>

          <p>
            (audio, software, and performance; 2020-ongoing)
            <br /><br />
            An interactive system for learning a little about gently interacting
            with chaotic and balanced states. The performance consists of making
            and releasing giant bubbles in loose synchronization. The software
            consists of two frequency sources and a shift register. One of the
            oscillators acts as a variable clock, and the other provides the
            input values for the shift register. Interactions between the two
            frequency sources create complex interference patterns that, when
            the output of the shift register is fed back into the frequency
            parameters of the oscillators, produce audio signals that are in
            between pitched and unpitched, an audibly warped clock. The feedback
            system seeks a balanced state—when this state is just slightly
            disturbed, the system takes time to find the next balanced state,
            and the sound appears to wander, split, stutter, etc. until it finds
            its balance. Each new balanced state is determined by the current
            steady state of the system's parameters, as well as its previous
            steady state. (Collaboration with Sarah Rara)
          </p>
        </div>

        <img
          class="icon"
          alt="A diagram showing different time scales as overlapping arcs segmenting a line. Short durations are marked with blue arcs, medium duration in green, and longer duration in red."
          src="https://cdn.glitch.global/a8abba79-5fe1-408e-a0a9-e56faa999b8e/71624078239420.png?v=1652548953423"
        />
        <div class="text">
          <h1>Music Against Generalization</h1>
          <audio controls>
            <source
              src="https://cdn.glitch.global/a8abba79-5fe1-408e-a0a9-e56faa999b8e/11624083979065.mp3?v=1652550419971"
            />
          </audio>
          <audio controls>
            <source
              src="https://cdn.glitch.global/a8abba79-5fe1-408e-a0a9-e56faa999b8e/71624084191340.mp3?v=1652550418052"
            />
          </audio>
          <audio controls>
            <source
              src="https://cdn.glitch.global/a8abba79-5fe1-408e-a0a9-e56faa999b8e/51624086790540.mp3?v=1652550415941"
            />
          </audio>
          <audio controls>
            <source
              src="https://cdn.glitch.global/a8abba79-5fe1-408e-a0a9-e56faa999b8e/01624091607619.mp3?v=1652550415941"
            />
          </audio>
          <audio controls>
            <source
              src="https://cdn.glitch.global/a8abba79-5fe1-408e-a0a9-e56faa999b8e/31624091300228.mp3?v=1652550409357"
            />
          </audio>

          <p>
            (audio, software, text, 2020-ongoing)
            <br />
            <br />
            Experiments with inference-based techniques for sound-making—sensory
            material that unfolds in time according to abstract representations
            of what is likely to occur in each successive moment: predicting the
            future based on the past. Using machine learning models to
            re-synthesize material from personal archives (hundreds of hours of
            sonic sketches, field recordings, and performance documentation) as
            well as methodical explorations of the same models without no
            conditioning (as in the examples provided here), this project seeks
            to uncover latent tendencies of the models used, as well as to
            recover temporalities, contexts, and affective currents tacit in the
            source material.

            <br />
            <br />
            <a
              href="https://learning.pubpub.org/pub/music-against-generalization"
              target="_blank"
              >Link to text and more examples</a
            >
          </p>
        </div>
        <img
          class="icon"
          alt="A brightly colored and blurry digital image vaguely resembling a face, or a pattern of blobs."
          src="https://cdn.glitch.global/61c0af97-9b71-4785-8528-358ec76ada8e/IMG_0097.jpeg?v=1693509356937"
        />
        <div class="text">
          <h1>Beyond Majority Rule</h1>
          <p>
            (Variable media. 2018-ongoing)
            <br />
            <br />
            <i>Beyond Majority Rule</i> began by surveying how non-hierarchical
            groups make decisions, with a particular curiosity as to how groups
            structured against representation might decide to visually or
            symbolically represent themselves and their common experience. The
            results, fictionalized and composited, point to a domain where to be
            represented means to be recognized—where collective memory and
            decision-making can be understood as forms of image recognition.
            Transitional and intermediate, these are images used in the way
            words are used when spoken, described in the way shadows describe
            the objects that cast them (The image shown here offers one example:
            facial recognition software used to generate faces rather than
            classify them).<br /><br /><a
              href="https://luckydragons.org/wp-content/uploads/2018/12/beyond_majority_rule.pdf"
              target="_blank"
              >link to pdf of collection</a
            >
          </p>
        </div>
        <div style="padding: 56.25% 0 0 0; position: relative">
          <iframe
            class="icon"
            src="https://player.vimeo.com/video/1031011022?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479"
            frameborder="0"
            allow="autoplay; fullscreen; picture-in-picture; clipboard-write"
            style="
              position: absolute;
              top: 0;
              left: 0;
              width: 100%;
              height: 100%;
            "
            title="visionreport"
          ></iframe>
        </div>
        <script src="https://player.vimeo.com/api/player.js"></script>
        <div class="text">
          <h1>Visionreport</h1>
          <p>
            (Software, performance, video, sound. 2017-ongoing)
            <br /><br />Techniques for the interplay of direct and
            computer-aided sensation, where the distinction between translation
            and interpretation is made ambiguous, flickering between human and
            algorithmic observation, and the activities of recognizing,
            modeling, and predicting are viewed as musical forms. Here, a
            handheld pen sketches lines in white across a black background,
            coinciding with short bursts of synthesized sound. The lines bend
            and waver at curves and angles, rising and falling to meet the
            modulating sound. These free-hand, ambiguous shapes may resemble
            letters or numbers, or intuited as either cause or effect of the
            sound. Each drawn figure is analyzed while in the process of being
            drawn. Probable future routes, indicated by fine, branching lines
            which proliferate where the lines end, render the set of all
            recognizable forms that each shape’s particular ambiguity might
            allow. When the pen lifts, predictions continue—lines spread, curve,
            and overlap, reaching to suggest a new course. (collaboration with
            Sarah Rara)<br /><br /><a
              href="https://luckydragons.org/category/visionreport/
  "
              target="_blank"
              >Link to view the collection</a
            >
          </p>
        </div>
        <img
          class="icon"
          alt="A group of five performers lying on a patchwork of orange fabric, seen from above and behind. The performers are laying on one another and spreading their arms to the sides, the feet of onlookers are visible in the background. a patch with the word 'observer' is sewed onto the orange fabric."
          src="https://cdn.glitch.global/61c0af97-9b71-4785-8528-358ec76ada8e/grupo-5-.jpg?v=1731998056196"
        />
        <div class="text">
          <h1>User Agreement</h1>
          <p>
            (Variable Media. 2016-ongoing)
            <br /><br />The purpose of this artwork is to reverse engineer the
            technologies of peace—treaties, protocols, symbols and systems—in
            order to learn from what has already been invented, to repurpose and
            re-contextualize, to create new possibilities for interaction, and
            to fix existing bugs. Working backwards from the ways peace has been
            put to use through images, actions, and language, we will unpack and
            re-imagine techniques of mediation, conflict resolution, and
            treaty-making as performances, workshops, and interventions.
            Translated, abstracted, dispersed—the goal is to develop and make
            available new technologies for peace, conditions for engagement that
            preserve difference and acknowledge unanswered questions.
            (collaboration with Sarah Rara)<br /><br /><a
              href="https://luckydragons.org/category/user-agreement/
  "
              target="_blank"
              >Link to view the collection</a
            >
          </p>
        </div>
        <img
          class="icon"
          alt="Lyrics printed in dense white text against a black background."
          src="https://cdn.glitch.global/61c0af97-9b71-4785-8528-358ec76ada8e/IMG_7951.jpeg?v=1693508641870"
        />
        <div class="text">
          <h1>Speak Your Own Language</h1>
          <p>
            (Audio, 2014-ongoing)
            <br />
            <br />
            <audio controls>
              <source
                src="https://www.dropbox.com/scl/fi/w0mefdz7mh5y9b99vsrok/02-track-2.mp3?rlkey=khsmmm12dbj0g3iyxxtvpa8wx&raw=1"
              />
            </audio>

            <audio controls>
              <source
                src="https://www.dropbox.com/scl/fi/yelubhxmr9jr9fvqbazbc/03-track-3.mp3?rlkey=77sfp706giqz8hdl7y7wcnbt2&raw=1"
              />
            </audio>
            <br /><br />
            A continuing exploration (in collaboration with artist-researcher
            Sarah Rara) of the auditory illusion—first described by psychologist
            Diana Deutsch—by which short fragments of speech, when repeated, can
            appear as entire words and sentences. Spoken syllables, sequenced,
            filtered, and layered into rhythms and harmonic textures, occupy an
            area between music and language that each listener hears
            differently. Our attention wanders and allows for a shift between
            what we hear and what we imagine—not as a puzzle to solve, but as
            information in raw form that we meet halfway as language or as
            music.
          </p>
        </div>
        <div style="padding: 56.25% 0 0 0; position: relative">
          <iframe
            class="icon"
            alt="Embedded video of performers making music by touching one another on the skin. Some performers hold metal contacts which are attached to a home-made synthesizer. The mood is playful and chaotic."
            src="https://player.vimeo.com/video/859961932?h=ca90577594&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479"
            frameborder="0"
            allow="autoplay; fullscreen; picture-in-picture"
            style="
              position: absolute;
              top: 0;
              left: 0;
              width: 100%;
              height: 100%;
            "
            title="lucky dragons navel"
          ></iframe>
        </div>
        <script src="https://player.vimeo.com/api/player.js"></script>
        <div class="text">
          <h1>Make a Baby</h1>
          <p>
            (software, hardware, interactive audio. 2004-ongoing)
            <br /><br />
            A synthesizer played by two or more people touching one another on
            the skin. (collaboration with Sarah Rara)
            <br /><br /><a
              href="https://luckydragons.org/category/make-a-baby/"
              target="_blank"
              >Link to view the collection</a
            >
          </p>
        </div>
        <div style="padding: 75% 0 0 0; position: relative">
          <iframe
            class="icon"
            src="https://player.vimeo.com/video/1031014260?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479"
            frameborder="0"
            allow="autoplay; fullscreen; picture-in-picture; clipboard-write"
            style="
              position: absolute;
              top: 0;
              left: 0;
              width: 100%;
              height: 100%;
            "
            title="sumi-noguchi"
          ></iframe>
        </div>
        <script src="https://player.vimeo.com/api/player.js"></script>
        <div class="text">
          <h1>Sumi Ink Club</h1>
          <p>
            (sumi ink, 2005-ongoing)
            <br /><br />
            A platform for collaborative art, Sumi Ink Club is non-hierarchical:
            all ages, all humans, all styles. The club produces work
            cooperatively in open-to-the-public meetings using Sumi Ink with
            brushes. We think of drawing together as a means to open and fortify
            social interactions that bleed into everyday life. Beginning with a
            core set of guidelines for collaboration, we create complex,
            composite images that represent our fantasies and express our
            histories. We hold conversations through drawing. These drawings are
            re-worked, displayed and distributed as murals, prints, textiles,
            garments, and zines. All images made by Sumi Ink Club belong to the
            public domain, designed to be shared.
            <br /><br /><a href="https://sumiink.club" target="_blank"
              >Link to project page</a
            >
          </p>
        </div>
      </div>
    </div>
  </body>
</html>
